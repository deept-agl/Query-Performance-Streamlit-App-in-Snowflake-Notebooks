{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "h5e7ycjifmokpapasbv2",
   "authorId": "5810321831746",
   "authorName": "DEEP",
   "authorEmail": "deeptiag013@gmail.com",
   "sessionId": "4a3b42c0-8a46-469c-98f6-9357de22e2b6",
   "lastEditTime": 1743922240328
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c278c920-1eea-41c3-a856-09def785b6fc",
   "metadata": {
    "name": "cell1",
    "collapsed": false
   },
   "source": "# Query Performance App in Snowflake Notebooks using Streamlit"
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "sql",
    "name": "sql_query"
   },
   "source": "select\nROW_NUMBER() OVER(ORDER BY partitions_scanned DESC) AS query_id_int,\nquery_id,\nquery_text,\ntotal_elapsed_time/1000 AS query_execution_time_seconds,\npartitions_scanned,\npartitions_total\nfrom snowflake.account_usage.query_history Q\nwhere warehouse_name='COMPUTE_WH' AND TO_DATE(Q.start_time)>DATEADD(day,-1,TO_DATE(CURRENT_TIMESTAMP()))\nAND total_elapsed_time > 0 --only get queries that actually used compute\nAND error_code IS NULL\nAND partitions_scanned IS NOT NULL\nORDER BY total_elapsed_time desc\nLIMIT 50;",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "f239691d-e2d1-4cf0-a592-0935dc7a3f30",
   "metadata": {
    "language": "python",
    "name": "imports"
   },
   "outputs": [],
   "source": "##Importing the libraries\n\nfrom snowflake.snowpark.context import get_active_session\nimport pandas as pd\nimport streamlit as st\nimport altair as alt\nimport numpy as np",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e8323ba1-7298-4b3b-a452-0a3fa42eaa8b",
   "metadata": {
    "language": "python",
    "name": "screen_design"
   },
   "outputs": [],
   "source": "st.title('Top n longest-running queries')\n\n# Input widgets\ncol = st.columns(3)\n\nwith col[0]:\n    timeframe_option = st.selectbox('Select a timeframe', ('day', 'week', 'month'))\n\nwith col[1]:\n    limit_option = st.slider('Display n rows', 10, 200, 100)\n\nwith col[2]:\n    bin_option = st.slider('Bin size', 1, 30, 10)\n\nsql_command_option = st.multiselect('Select a SQL command to analyze', \n                                  ['describe', 'execute', 'show', 'PUT', 'SELECT'],\n                                  ['describe', 'show'])\n\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "python",
    "name": "retrieve_data"
   },
   "source": "\n# Data retrieval\nsession = get_active_session()\ndf = session.sql(\n    f\"\"\"\n    select\n        ROW_NUMBER() OVER(ORDER BY partitions_scanned DESC) AS query_id_int,\n        query_id,\n        query_text,\n        total_elapsed_time/1000 AS query_execution_time_seconds,\n        partitions_scanned,\n        partitions_total\n    from snowflake.account_usage.query_history Q\n    where warehouse_name='COMPUTE_WH' AND TO_DATE(Q.start_time)>DATEADD(day,-1,TO_DATE(CURRENT_TIMESTAMP()))\n        AND total_elapsed_time > 0 --only get queries that actually used compute\n        AND error_code IS NULL\n        AND partitions_scanned IS NOT NULL\n    ORDER BY total_elapsed_time desc\n    LIMIT {limit_option};\n    \"\"\"\n    ).to_pandas()\n\ndf = df[df['QUERY_TEXT'].str.lower().str.startswith(tuple(commands.lower() for commands in sql_command_option))]",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "836aef8a-8939-4bf5-8d25-47b1eb311e84",
   "metadata": {
    "language": "python",
    "name": "visualize"
   },
   "outputs": [],
   "source": "st.title('Histogram of Query Execution Times')\n\n# Create a DataFrame for the histogram data\nhist, bin_edges = np.histogram(df['QUERY_EXECUTION_TIME_SECONDS'], bins=bin_option)\n\nhistogram_df = pd.DataFrame({\n    'bin_start': bin_edges[:-1],\n    'bin_end': bin_edges[1:],\n    'count': hist\n})\nhistogram_df['bin_label'] = histogram_df.apply(lambda row: f\"{row['bin_start']:.2f} - {row['bin_end']:.2f}\", axis=1)\n\n# Create plots\nhistogram_plot = alt.Chart(histogram_df).mark_bar().encode(\n    x=alt.X('bin_label:N', sort=histogram_df['bin_label'].tolist(),\n            axis=alt.Axis(title='QUERY_EXECUTION_TIME_SECONDS', labelAngle=90)),\n    y=alt.Y('count:Q', axis=alt.Axis(title='Count')),\n    tooltip=['bin_label', 'count']\n)\n\nbox_plot = alt.Chart(df).mark_boxplot(\n    extent=\"min-max\",\n    color='yellow'\n).encode(\n    alt.X(\"QUERY_EXECUTION_TIME_SECONDS:Q\", scale=alt.Scale(zero=False))\n).properties(\n    height=200\n)\n\nst.altair_chart(histogram_plot, use_container_width=True)\nst.altair_chart(box_plot, use_container_width=True)\n\n\n# Data display\nwith st.expander('Show data'):\n    st.dataframe(df)\nwith st.expander('Show summary statistics'):\n    st.write(df['QUERY_EXECUTION_TIME_SECONDS'].describe())",
   "execution_count": null
  }
 ]
}